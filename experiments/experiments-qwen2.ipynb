{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ff31df-f61f-452c-aeea-bc335b7ec3ac",
   "metadata": {},
   "source": [
    "# RAG Technique Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "813b1a13-a589-4317-a331-e190e0ce2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import qdrant_client\n",
    "\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.core.extractors import QuestionsAnsweredExtractor\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import torch\n",
    "from llama_index.core.llama_dataset import (\n",
    "    LabelledRagDataset,\n",
    "    CreatedBy,\n",
    "    CreatedByType,\n",
    "    LabelledRagDataExample,\n",
    ")\n",
    "from llama_index.core.llama_pack import download_llama_pack\n",
    "import inspect\n",
    "from qdrant_client import QdrantClient, AsyncQdrantClient\n",
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "from llama_index.core.vector_stores.types import VectorStoreQuery\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1a22d989-6431-430d-af1d-5c7dc9454c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import is required for asynchronous functions to work\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647d3f3-c411-4eb3-bf2f-2110d18dfdb4",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34253322-f2a8-450a-b749-d7b7720ad4ee",
   "metadata": {},
   "source": [
    "### Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "810f4cd4-4fa3-4a3a-90c6-77f28694401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"qwen2:0.5b\"\n",
    "LLM = Ollama(model=LLM_MODEL, request_timeout=36000.0)\n",
    "Settings.llm = LLM\n",
    "EMBED_MODEL = os.environ.get(\"EMBED_MODEL\", \"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "850fa4e5-1c12-4132-bc66-674b1e8406eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2d79a554fa4ccaaee307b1f78bf68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBED_MODEL = os.environ.get(\"EMBED_MODEL\", \"BAAI/bge-base-en-v1.5\")\n",
    "Settings.embed_model = FastEmbedEmbedding(model_name=EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "45500c17-0793-44bb-ae80-5ff05947d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "RERANK_MODEL = SentenceTransformerRerank(top_n=2, model=\"BAAI/bge-reranker-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c06405-ab3a-4931-b777-b0665b1f244b",
   "metadata": {},
   "source": [
    "### Vector Store Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "502545a5-cd79-460e-b7d0-d21e1f597adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_HOST = os.environ.get(\"QDRANT_HOST\", \"localhost\")\n",
    "QDRANT_PORT = os.environ.get(\"PORT\", 6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "17a78177-0722-4765-9809-479ea585eeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='style_python')])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_CLIENT = qdrant_client.QdrantClient(\n",
    "    # location=\":memory:\"\n",
    "    host=QDRANT_HOST,\n",
    "    port=QDRANT_PORT,\n",
    ")\n",
    "QDRANT_CLIENT.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1fd71905-c6d9-46b6-aab9-585289a81fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='style_python')])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_CLIENT_ASYNC = qdrant_client.AsyncQdrantClient(\n",
    "    # location=\":memory:\"\n",
    "    host=QDRANT_HOST,\n",
    "    port=QDRANT_PORT,\n",
    ")\n",
    "await QDRANT_CLIENT_ASYNC.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "11a25c59-4f59-4496-bde8-31e96e1acabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both client and aclient are provided. If using `:memory:` mode, the data between clients is not synced.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d093fba83b4513b2c520f79bc32451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0581da2a878d4df5a32a7b543a214629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cca577429cf44d0bd234f3a9dce1092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856b6297b04442f3a369a740240346f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(\n",
    "    client=QDRANT_CLIENT,\n",
    "    aclient=QDRANT_CLIENT_ASYNC,\n",
    "    enable_hybrid=True,\n",
    "    collection_name=\"style_python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "78ff8ac4-7afd-4fd0-8a7e-fcd293f9a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "744e69b0-4db3-4529-86a8-5ae43bd8eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Should I always use parentheses around tuples?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a6763-f5e8-4f1d-8d43-6163b5c0e027",
   "metadata": {},
   "source": [
    "### Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e8db3ce3-420e-4d7a-ade5-fcac16769a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_basic = index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    sparse_top_k=12,\n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "371602db-2d44-474d-b0fc-13f79c693dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No. In Python, tuples are enclosed in parentheses when you need them to be treated as a group of items that can't be modified after they have been assigned values. This is true for all types of expressions and variables used in Python. You should not use parentheses around tuples unless explicitly told otherwise by the interpreter or your application.\""
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine_basic.query(query)\n",
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "289703bc-3d88-4aa3-b2c3-d7cde993cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_hybrid = index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    sparse_top_k=12,\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e44851da-b6d3-4465-8b5a-9a2af5ec722f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, you should always use parentheses around tuples to indicate that a tuple is being treated as a collection of objects in the same order. This helps prevent confusion between tuple elements and other types of variable that can be combined into a single object within a tuple. By doing so, you avoid using multiple types for one object, which is often not desirable when working with collections like tuples.'"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine_hybrid.query(query)\n",
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "722cfb9b-b9e6-475f-a9f3-0603b9af9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_rerank = index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    sparse_top_k=12,\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    node_postprocessors=[rerank],\n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3720ab6a-4211-41a4-9745-6bb5a4f5bc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, it is fine to use parentheses around tuples when using Python syntax in this context. The context also mentions that typed lists can only contain objects of a single type, so it is acceptable to use parentheses around these types as well.\\n\\nHowever, for more complex or nested types within tuple, it might be more efficient and readable to use parentheses around these elements.'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine_rerank.query(query)\n",
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "972415d9-fdb3-439d-b27e-1a1a36c39e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engines = [\n",
    "    (\"basic\", query_engine_basic),\n",
    "    (\"hybrid\",query_engine_hybrid),\n",
    "    (\"rerank\",query_engine_rerank)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a3d4f-1585-41fc-b8eb-d71bf530826e",
   "metadata": {},
   "source": [
    "### Test 1 - Evaluate Correctness, Relevancy, Faithfulness, Context Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b694a000-5c50-4d1b-9ec7-7afe7d691131",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset = LabelledRagDataset.from_json(\"data/testsets/style_guide_testset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb442b6-3227-4175-90f3-d0a92bc69e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "RagEvaluatorPack = download_llama_pack(\"RagEvaluatorPack\", \"./pack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "6f6d1115-4f9c-4cfc-80f7-2bf999cae6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (query_engine: llama_index.core.base.base_query_engine.BaseQueryEngine, rag_dataset: llama_index.core.llama_dataset.base.BaseLlamaDataset, judge_llm: Optional[llama_index.core.llms.llm.LLM] = None, embed_model: Optional[llama_index.core.base.embeddings.base.BaseEmbedding] = None, show_progress: bool = True, result_path: Optional[str] = None)>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.signature(RagEvaluatorPack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1acb4263-c4eb-493a-b219-76892aa076e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_evaluator_basic = RagEvaluatorPack(\n",
    "    query_engine=query_engine,  # built with the same source Documents as the rag_dataset\n",
    "    rag_dataset=rag_dataset,\n",
    "    judge_llm=Settings.llm,\n",
    "    embed_model=Settings.embed_model,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "53e8f94a-bec3-4a45-abea-439b83d01f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_evaluator_hybrid = RagEvaluatorPack(\n",
    "    query_engine=query_engine_hybrid,  # built with the same source Documents as the rag_dataset\n",
    "    rag_dataset=rag_dataset,\n",
    "    judge_llm=Settings.llm,\n",
    "    embed_model=Settings.embed_model,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "df47a434-c9ac-4666-a7e7-7a6b9c310b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_evaluator_rerank = RagEvaluatorPack(\n",
    "    query_engine=query_engine_rerank,  # built with the same source Documents as the rag_dataset\n",
    "    rag_dataset=rag_dataset,\n",
    "    judge_llm=Settings.llm,\n",
    "    embed_model=Settings.embed_model,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "2179a071-df95-45ed-a2fd-995813ed2749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.06it/s]\n",
      "2it [00:02,  1.25s/it]\n",
      "2it [00:02,  1.23s/it]\n",
      "2it [00:02,  1.16s/it]\n",
      "2it [00:02,  1.23s/it]\n",
      "1it [00:01,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "benchmark_df_basic = rag_evaluator_basic.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4ea075c7-d8aa-4ee7-b42f-a18c11bb9736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.19s/it]\n",
      "2it [00:02,  1.27s/it]\n",
      "2it [00:03,  1.59s/it]\n",
      "2it [00:02,  1.26s/it]\n",
      "2it [00:02,  1.26s/it]\n",
      "1it [00:01,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "benchmark_df_hybrid = rag_evaluator_hybrid.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "23084124-c3a1-4c43-a81d-d15c651d6df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.05s/it]\n",
      "2it [00:02,  1.22s/it]\n",
      "2it [00:02,  1.13s/it]\n",
      "2it [00:02,  1.08s/it]\n",
      "2it [00:02,  1.26s/it]\n",
      "1it [00:01,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "benchmark_df_rerank = rag_evaluator_rerank.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ea848fe3-f121-4050-9850-7059c3409bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag                            base_rag\n",
      "metrics                                \n",
      "mean_correctness_score         2.363636\n",
      "mean_relevancy_score           0.545455\n",
      "mean_faithfulness_score        0.454545\n",
      "mean_context_similarity_score  0.831865\n",
      "\n",
      "rag                            base_rag\n",
      "metrics                                \n",
      "mean_correctness_score         2.909091\n",
      "mean_relevancy_score           0.545455\n",
      "mean_faithfulness_score        0.272727\n",
      "mean_context_similarity_score  0.831865\n",
      "\n",
      "rag                            base_rag\n",
      "metrics                                \n",
      "mean_correctness_score         2.916667\n",
      "mean_relevancy_score           0.333333\n",
      "mean_faithfulness_score        0.333333\n",
      "mean_context_similarity_score  0.837198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = [benchmark_df_basic, benchmark_df_hybrid, benchmark_df_rerank]\n",
    "for result_df in benchmark_results:\n",
    "    print(result_df.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7dd6e-3265-42c1-984b-e64ae1f6aee3",
   "metadata": {},
   "source": [
    "### Test 2 - Evaluate Hit Rate and Maximum Marginal Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "36843026-a5d0-4a40-b8e0-304406585b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_async = VectorStoreIndex.from_vector_store(vector_store=vector_store, use_async=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "1af41bb6-88c9-42ea-bd85-bc0d2d5d8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index_async.as_retriever(\n",
    "    similarity_top_k=2,\n",
    "    sparse_top_k=12,\n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "5e812bc5-a24f-4996-9f1d-274cc7ed98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_hybrid = index_async.as_retriever(\n",
    "    similarity_top_k=2,\n",
    "    sparse_top_k=12,\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "83c53eb6-1308-48d0-9657-49daa38521d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_rerank = index_async.as_retriever(\n",
    "    similarity_top_k=2,\n",
    "    sparse_top_k=12,\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    node_postprocessors=[rerank],\n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3e70245f-2bfc-4acb-8a66-fbf16c36190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook assumes you have already made this for your VectorStore\n",
    "# If not, run this function on your VectorStore\n",
    "def create_and_save_test_dataset():\n",
    "    nodes = vector_store.get_nodes()\n",
    "    qa_dataset = generate_question_context_pairs(\n",
    "        nodes, llm=Settings.llm, num_questions_per_chunk=1\n",
    "    )\n",
    "    qa_dataset.save_json(\"qa_dataset.json\")\n",
    "    return qa_dataset\n",
    "# qa_dataset=create_and_save_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "8316827c-1e70-4681-a143-4174bc8d6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]\n",
    "# metrics = [\"mrr\", \"hit_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "65e81adf-a549-41c1-a02a-bc1a519f4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=retriever, use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b18c769b-ad59-4254-b3fa-e0054576cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_evaluator_hybrid = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=retriever_hybrid, use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "911513d1-355f-44db-8233-e5e003d11ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_evaluator_rerank = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=retriever_rerank, use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4541ecb9-748b-40cb-84c5-7b8344d8351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (query: str, expected_ids: List[str], expected_texts: Optional[List[str]] = None, mode: llama_index.core.evaluation.retrieval.base.RetrievalEvalMode = <RetrievalEvalMode.TEXT: 'text'>, **kwargs: Any) -> llama_index.core.evaluation.retrieval.base.RetrievalEvalResult>"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.signature(retriever_evaluator.aevaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "587b3d71-23d4-49c2-873a-b1b1ffb556a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█\n"
     ]
    }
   ],
   "source": [
    "eval_results_basic = await retriever_evaluator.aevaluate_dataset(dataset=qa_dataset, workers=10, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "912bb96b-1fff-4a00-8d19-41b347abb94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█\n"
     ]
    }
   ],
   "source": [
    "eval_results_hybrid = await retriever_evaluator_hybrid.aevaluate_dataset(dataset=qa_dataset, workers=10, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "4d456bef-dc16-42cf-8dd1-c8fca1889868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█\n"
     ]
    }
   ],
   "source": [
    "eval_results_rerank = await retriever_evaluator_rerank.aevaluate_dataset(dataset=qa_dataset, workers=10, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "acce7c79-ffe1-4f6d-9ec2-29a7eda41d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(name, eval_results):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "    columns = {\n",
    "        \"retrievers\": [name],\n",
    "        **{k: [full_df[k].mean()] for k in metrics},\n",
    "    }\n",
    "\n",
    "    # if include_cohere_rerank:\n",
    "    #     crr_relevancy = full_df[\"cohere_rerank_relevancy\"].mean()\n",
    "    #     columns.update({\"cohere_rerank_relevancy\": [crr_relevancy]})\n",
    "\n",
    "    metric_df = pd.DataFrame(columns)\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "2ae44d2e-38e8-4b3c-b0b8-31890a8f105e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Retriever</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>0.25817</td>\n",
       "      <td>0.140523</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>0.25817</td>\n",
       "      <td>0.161969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        retrievers  hit_rate      mrr  precision    recall       ap      ndcg\n",
       "0  Basic Retriever  0.281046  0.25817   0.140523  0.281046  0.25817  0.161969"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_results(\"Basic Retriever\", eval_results_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2c52f45c-38eb-47d9-87e4-a1e4b7a73e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hybrid Retriever</td>\n",
       "      <td>0.27451</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.27451</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.159441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         retrievers  hit_rate       mrr  precision   recall        ap  \\\n",
       "0  Hybrid Retriever   0.27451  0.254902   0.137255  0.27451  0.254902   \n",
       "\n",
       "       ndcg  \n",
       "0  0.159441  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_results(\"Hybrid Retriever\", eval_results_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "d177dee5-20e9-4cd5-b627-5e7d49423bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rerank Retriever</td>\n",
       "      <td>0.27451</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.27451</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.159441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         retrievers  hit_rate       mrr  precision   recall        ap  \\\n",
       "0  Rerank Retriever   0.27451  0.254902   0.137255  0.27451  0.254902   \n",
       "\n",
       "       ndcg  \n",
       "0  0.159441  "
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_results(\"Rerank Retriever\", eval_results_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94e3c9-99b2-4478-8249-33145c968e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
